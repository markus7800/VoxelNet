{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from molloader import *\n",
    "from ML_utils import *\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, ParameterGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_duplicates(df):\n",
    "    df = df.drop_duplicates(subset=\"compound\", keep=\"first\")\n",
    "    print(\"Number of molecules\", df.shape[0])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_elements(df):\n",
    "      return np.unique(np.hstack(np.array(df.species)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VoxelNet(nn.Module):\n",
    "    def __init__(self, in_channels=1):\n",
    "        super().__init__()\n",
    "        # (N, C, D, H, W)\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, 16, 3, padding=0, stride=1),\n",
    "            nn.SELU(0.3),\n",
    "            nn.MaxPool3d(2))\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv3d(16, 16, 3, padding=0, stride=1),\n",
    "            nn.SELU(),\n",
    "            nn.MaxPool3d(2))\n",
    "        \n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv3d(16, 16, 3, padding=0, stride=1),\n",
    "            nn.SELU())\n",
    "        \n",
    "        self.regressor = nn.Sequential(nn.Flatten(),\n",
    "                                        nn.Linear(1024, 32),\n",
    "                                        nn.SELU(),\n",
    "                                        nn.Linear(32, 8),\n",
    "                                        nn.SELU(),\n",
    "                                        nn.Linear(8, 1))\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.regressor(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = \"all_221_cp5_3_species_oxides\"\n",
    "fig_folder = \"plots_SELU/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of molecules 1983\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auid</th>\n",
       "      <th>aurl</th>\n",
       "      <th>compound</th>\n",
       "      <th>composition</th>\n",
       "      <th>species</th>\n",
       "      <th>natoms</th>\n",
       "      <th>spacegroup</th>\n",
       "      <th>pearson_symbol</th>\n",
       "      <th>geometry</th>\n",
       "      <th>positions_fractional</th>\n",
       "      <th>positions_cartesian</th>\n",
       "      <th>enthalpy_atom</th>\n",
       "      <th>enthalpy_formation_atom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aflow:b778fabdb1b01db1</td>\n",
       "      <td>aflowlib.duke.edu:AFLOWDATA/LIB3_RAW/AgAlO/T00...</td>\n",
       "      <td>Ag1Al1O3</td>\n",
       "      <td>[1, 1, 3]</td>\n",
       "      <td>[Ag, Al, O]</td>\n",
       "      <td>5</td>\n",
       "      <td>221</td>\n",
       "      <td>cP5</td>\n",
       "      <td>[3.7688035, 3.7688035, 3.7688035, 90.0, 90.0, ...</td>\n",
       "      <td>[[0.0, 0.0, 0.0], [0.5, 0.5, 0.5], [0.0, 0.5, ...</td>\n",
       "      <td>[[0.0, 0.0, 0.0], [1.8844, 1.8844, 1.8844], [0...</td>\n",
       "      <td>-5.04863</td>\n",
       "      <td>-0.775736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aflow:272cd0e74db84a51</td>\n",
       "      <td>aflowlib.duke.edu:AFLOWDATA/LIB3_RAW/AgAsO/T00...</td>\n",
       "      <td>Ag1As1O3</td>\n",
       "      <td>[1, 1, 3]</td>\n",
       "      <td>[Ag, As, O]</td>\n",
       "      <td>5</td>\n",
       "      <td>221</td>\n",
       "      <td>cP5</td>\n",
       "      <td>[3.7951634, 3.7951634, 3.7951634, 90.0, 90.0, ...</td>\n",
       "      <td>[[0.0, 0.0, 0.0], [0.5, 0.5, 0.5], [0.0, 0.5, ...</td>\n",
       "      <td>[[0.0, 0.0, 0.0], [1.89758, 1.89758, 1.89758],...</td>\n",
       "      <td>-4.55519</td>\n",
       "      <td>-0.100528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aflow:7e6bdbc495310b44</td>\n",
       "      <td>aflowlib.duke.edu:AFLOWDATA/LIB3_RAW/AgAuO/T00...</td>\n",
       "      <td>Ag1Au1O3</td>\n",
       "      <td>[1, 1, 3]</td>\n",
       "      <td>[Ag, Au, O]</td>\n",
       "      <td>5</td>\n",
       "      <td>221</td>\n",
       "      <td>cP5</td>\n",
       "      <td>[4.1003175, 4.1003175, 4.1003175, 90.0, 90.0, ...</td>\n",
       "      <td>[[0.0, 0.0, 0.0], [0.5, 0.5, 0.5], [0.0, 0.5, ...</td>\n",
       "      <td>[[0.0, 0.0, 0.0], [2.05016, 2.05016, 2.05016],...</td>\n",
       "      <td>-2.80408</td>\n",
       "      <td>1.37453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>aflow:c0e1c25976bb4c75</td>\n",
       "      <td>aflowlib.duke.edu:AFLOWDATA/LIB3_RAW/AgB_hO/T0...</td>\n",
       "      <td>Ag1B1O3</td>\n",
       "      <td>[1, 1, 3]</td>\n",
       "      <td>[Ag, B, O]</td>\n",
       "      <td>5</td>\n",
       "      <td>221</td>\n",
       "      <td>cP5</td>\n",
       "      <td>[3.484261, 3.484261, 3.484261, 90.0, 90.0, 90.0]</td>\n",
       "      <td>[[0.0, 0.0, 0.0], [0.5, 0.5, 0.5], [0.0, 0.5, ...</td>\n",
       "      <td>[[0.0, 0.0, 0.0], [1.74213, 1.74213, 1.74213],...</td>\n",
       "      <td>-4.55549</td>\n",
       "      <td>0.30734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>aflow:3b79b8b28a5d5cc1</td>\n",
       "      <td>aflowlib.duke.edu:AFLOWDATA/LIB3_RAW/AgBa_svO/...</td>\n",
       "      <td>Ag1Ba1O3</td>\n",
       "      <td>[1, 1, 3]</td>\n",
       "      <td>[Ag, Ba, O]</td>\n",
       "      <td>5</td>\n",
       "      <td>221</td>\n",
       "      <td>cP5</td>\n",
       "      <td>[4.7271734, 4.7271734, 4.7271734, 90.0, 90.0, ...</td>\n",
       "      <td>[[-0.0, 0.0, -0.0], [0.5, 0.5, 0.5], [-0.0, 0....</td>\n",
       "      <td>[[-0.0, 0.0, -0.0], [2.36359, 2.36359, 2.36359...</td>\n",
       "      <td>-3.52096</td>\n",
       "      <td>0.388015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3947</th>\n",
       "      <td>aflow:e243d024b0749ac0</td>\n",
       "      <td>aflowlib.duke.edu:AFLOWDATA/LIB3_RAW/OXeZn/T00...</td>\n",
       "      <td>O3Xe1Zn1</td>\n",
       "      <td>[3, 1, 1]</td>\n",
       "      <td>[O, Xe, Zn]</td>\n",
       "      <td>5</td>\n",
       "      <td>221</td>\n",
       "      <td>cP5</td>\n",
       "      <td>[4.370543, 4.370543, 4.370543, 90.0, 90.0, 90.0]</td>\n",
       "      <td>[[0.0, 0.5, 0.5], [0.5, 0.0, 0.5], [0.5, 0.5, ...</td>\n",
       "      <td>[[0.0, 2.18527, 2.18527], [2.18527, 0.0, 2.185...</td>\n",
       "      <td>-1.89960</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3949</th>\n",
       "      <td>aflow:ae4a07b2d68c2933</td>\n",
       "      <td>aflowlib.duke.edu:AFLOWDATA/LIB3_RAW/OXeZr_sv/...</td>\n",
       "      <td>O3Xe1Zr1</td>\n",
       "      <td>[3, 1, 1]</td>\n",
       "      <td>[O, Xe, Zr]</td>\n",
       "      <td>5</td>\n",
       "      <td>221</td>\n",
       "      <td>cP5</td>\n",
       "      <td>[4.322477, 4.322477, 4.322477, 90.0, 90.0, 90.0]</td>\n",
       "      <td>[[0.0, 0.5, 0.5], [0.5, 0.0, 0.5], [0.5, 0.5, ...</td>\n",
       "      <td>[[-0.0, 2.16124, 2.16124], [2.16124, -0.0, 2.1...</td>\n",
       "      <td>-5.89112</td>\n",
       "      <td>-1.222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3951</th>\n",
       "      <td>aflow:0d9d3ce033a32aae</td>\n",
       "      <td>aflowlib.duke.edu:AFLOWDATA/LIB3_RAW/OY_svZn/T...</td>\n",
       "      <td>O3Y1Zn1</td>\n",
       "      <td>[3, 1, 1]</td>\n",
       "      <td>[O, Y, Zn]</td>\n",
       "      <td>5</td>\n",
       "      <td>221</td>\n",
       "      <td>cP5</td>\n",
       "      <td>[4.3517566, 4.3517566, 4.3517566, 90.0, 90.0, ...</td>\n",
       "      <td>[[0.0, 0.5, 0.5], [0.5, 0.0, 0.5], [0.5, 0.5, ...</td>\n",
       "      <td>[[0.0, 2.17588, 2.17588], [2.17588, 0.0, 2.175...</td>\n",
       "      <td>-5.57716</td>\n",
       "      <td>-1.07268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3953</th>\n",
       "      <td>aflow:627232532ed2fb40</td>\n",
       "      <td>aflowlib.duke.edu:AFLOWDATA/LIB3_RAW/OY_svZr_s...</td>\n",
       "      <td>O3Y1Zr1</td>\n",
       "      <td>[3, 1, 1]</td>\n",
       "      <td>[O, Y, Zr]</td>\n",
       "      <td>5</td>\n",
       "      <td>221</td>\n",
       "      <td>cP5</td>\n",
       "      <td>[4.155165, 4.155165, 4.155165, 90.0, 90.0, 90.0]</td>\n",
       "      <td>[[0.0, 0.5, 0.5], [0.5, 0.0, 0.5], [0.5, 0.5, ...</td>\n",
       "      <td>[[0.0, 2.07758, 2.07758], [2.07758, 0.0, 2.077...</td>\n",
       "      <td>-8.70129</td>\n",
       "      <td>-2.74124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3955</th>\n",
       "      <td>aflow:2b3ea96a80ac45cd</td>\n",
       "      <td>aflowlib.duke.edu:AFLOWDATA/LIB3_RAW/OZnZr_sv/...</td>\n",
       "      <td>O3Zn1Zr1</td>\n",
       "      <td>[3, 1, 1]</td>\n",
       "      <td>[O, Zn, Zr]</td>\n",
       "      <td>5</td>\n",
       "      <td>221</td>\n",
       "      <td>cP5</td>\n",
       "      <td>[3.723766, 3.723766, 3.723766, 90.0, 90.0, 90.0]</td>\n",
       "      <td>[[0.0, 0.5, 0.5], [0.5, 0.0, 0.5], [0.5, 0.5, ...</td>\n",
       "      <td>[[-0.0, 1.86188, 1.86188], [1.86188, -0.0, 1.8...</td>\n",
       "      <td>-6.45445</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1983 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        auid  \\\n",
       "0     aflow:b778fabdb1b01db1   \n",
       "2     aflow:272cd0e74db84a51   \n",
       "4     aflow:7e6bdbc495310b44   \n",
       "6     aflow:c0e1c25976bb4c75   \n",
       "8     aflow:3b79b8b28a5d5cc1   \n",
       "...                      ...   \n",
       "3947  aflow:e243d024b0749ac0   \n",
       "3949  aflow:ae4a07b2d68c2933   \n",
       "3951  aflow:0d9d3ce033a32aae   \n",
       "3953  aflow:627232532ed2fb40   \n",
       "3955  aflow:2b3ea96a80ac45cd   \n",
       "\n",
       "                                                   aurl  compound composition  \\\n",
       "0     aflowlib.duke.edu:AFLOWDATA/LIB3_RAW/AgAlO/T00...  Ag1Al1O3   [1, 1, 3]   \n",
       "2     aflowlib.duke.edu:AFLOWDATA/LIB3_RAW/AgAsO/T00...  Ag1As1O3   [1, 1, 3]   \n",
       "4     aflowlib.duke.edu:AFLOWDATA/LIB3_RAW/AgAuO/T00...  Ag1Au1O3   [1, 1, 3]   \n",
       "6     aflowlib.duke.edu:AFLOWDATA/LIB3_RAW/AgB_hO/T0...   Ag1B1O3   [1, 1, 3]   \n",
       "8     aflowlib.duke.edu:AFLOWDATA/LIB3_RAW/AgBa_svO/...  Ag1Ba1O3   [1, 1, 3]   \n",
       "...                                                 ...       ...         ...   \n",
       "3947  aflowlib.duke.edu:AFLOWDATA/LIB3_RAW/OXeZn/T00...  O3Xe1Zn1   [3, 1, 1]   \n",
       "3949  aflowlib.duke.edu:AFLOWDATA/LIB3_RAW/OXeZr_sv/...  O3Xe1Zr1   [3, 1, 1]   \n",
       "3951  aflowlib.duke.edu:AFLOWDATA/LIB3_RAW/OY_svZn/T...   O3Y1Zn1   [3, 1, 1]   \n",
       "3953  aflowlib.duke.edu:AFLOWDATA/LIB3_RAW/OY_svZr_s...   O3Y1Zr1   [3, 1, 1]   \n",
       "3955  aflowlib.duke.edu:AFLOWDATA/LIB3_RAW/OZnZr_sv/...  O3Zn1Zr1   [3, 1, 1]   \n",
       "\n",
       "          species natoms spacegroup pearson_symbol  \\\n",
       "0     [Ag, Al, O]      5        221            cP5   \n",
       "2     [Ag, As, O]      5        221            cP5   \n",
       "4     [Ag, Au, O]      5        221            cP5   \n",
       "6      [Ag, B, O]      5        221            cP5   \n",
       "8     [Ag, Ba, O]      5        221            cP5   \n",
       "...           ...    ...        ...            ...   \n",
       "3947  [O, Xe, Zn]      5        221            cP5   \n",
       "3949  [O, Xe, Zr]      5        221            cP5   \n",
       "3951   [O, Y, Zn]      5        221            cP5   \n",
       "3953   [O, Y, Zr]      5        221            cP5   \n",
       "3955  [O, Zn, Zr]      5        221            cP5   \n",
       "\n",
       "                                               geometry  \\\n",
       "0     [3.7688035, 3.7688035, 3.7688035, 90.0, 90.0, ...   \n",
       "2     [3.7951634, 3.7951634, 3.7951634, 90.0, 90.0, ...   \n",
       "4     [4.1003175, 4.1003175, 4.1003175, 90.0, 90.0, ...   \n",
       "6      [3.484261, 3.484261, 3.484261, 90.0, 90.0, 90.0]   \n",
       "8     [4.7271734, 4.7271734, 4.7271734, 90.0, 90.0, ...   \n",
       "...                                                 ...   \n",
       "3947   [4.370543, 4.370543, 4.370543, 90.0, 90.0, 90.0]   \n",
       "3949   [4.322477, 4.322477, 4.322477, 90.0, 90.0, 90.0]   \n",
       "3951  [4.3517566, 4.3517566, 4.3517566, 90.0, 90.0, ...   \n",
       "3953   [4.155165, 4.155165, 4.155165, 90.0, 90.0, 90.0]   \n",
       "3955   [3.723766, 3.723766, 3.723766, 90.0, 90.0, 90.0]   \n",
       "\n",
       "                                   positions_fractional  \\\n",
       "0     [[0.0, 0.0, 0.0], [0.5, 0.5, 0.5], [0.0, 0.5, ...   \n",
       "2     [[0.0, 0.0, 0.0], [0.5, 0.5, 0.5], [0.0, 0.5, ...   \n",
       "4     [[0.0, 0.0, 0.0], [0.5, 0.5, 0.5], [0.0, 0.5, ...   \n",
       "6     [[0.0, 0.0, 0.0], [0.5, 0.5, 0.5], [0.0, 0.5, ...   \n",
       "8     [[-0.0, 0.0, -0.0], [0.5, 0.5, 0.5], [-0.0, 0....   \n",
       "...                                                 ...   \n",
       "3947  [[0.0, 0.5, 0.5], [0.5, 0.0, 0.5], [0.5, 0.5, ...   \n",
       "3949  [[0.0, 0.5, 0.5], [0.5, 0.0, 0.5], [0.5, 0.5, ...   \n",
       "3951  [[0.0, 0.5, 0.5], [0.5, 0.0, 0.5], [0.5, 0.5, ...   \n",
       "3953  [[0.0, 0.5, 0.5], [0.5, 0.0, 0.5], [0.5, 0.5, ...   \n",
       "3955  [[0.0, 0.5, 0.5], [0.5, 0.0, 0.5], [0.5, 0.5, ...   \n",
       "\n",
       "                                    positions_cartesian  enthalpy_atom  \\\n",
       "0     [[0.0, 0.0, 0.0], [1.8844, 1.8844, 1.8844], [0...       -5.04863   \n",
       "2     [[0.0, 0.0, 0.0], [1.89758, 1.89758, 1.89758],...       -4.55519   \n",
       "4     [[0.0, 0.0, 0.0], [2.05016, 2.05016, 2.05016],...       -2.80408   \n",
       "6     [[0.0, 0.0, 0.0], [1.74213, 1.74213, 1.74213],...       -4.55549   \n",
       "8     [[-0.0, 0.0, -0.0], [2.36359, 2.36359, 2.36359...       -3.52096   \n",
       "...                                                 ...            ...   \n",
       "3947  [[0.0, 2.18527, 2.18527], [2.18527, 0.0, 2.185...       -1.89960   \n",
       "3949  [[-0.0, 2.16124, 2.16124], [2.16124, -0.0, 2.1...       -5.89112   \n",
       "3951  [[0.0, 2.17588, 2.17588], [2.17588, 0.0, 2.175...       -5.57716   \n",
       "3953  [[0.0, 2.07758, 2.07758], [2.07758, 0.0, 2.077...       -8.70129   \n",
       "3955  [[-0.0, 1.86188, 1.86188], [1.86188, -0.0, 1.8...       -6.45445   \n",
       "\n",
       "     enthalpy_formation_atom  \n",
       "0                  -0.775736  \n",
       "2                  -0.100528  \n",
       "4                    1.37453  \n",
       "6                    0.30734  \n",
       "8                   0.388015  \n",
       "...                      ...  \n",
       "3947                    None  \n",
       "3949                  -1.222  \n",
       "3951                -1.07268  \n",
       "3953                -2.74124  \n",
       "3955                    None  \n",
       "\n",
       "[1983 rows x 13 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(f\"data/{data_name}.pkl\")\n",
    "df = drop_duplicates(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79,\n",
       " array(['Ag', 'Al', 'As', 'Au', 'B', 'Ba', 'Be', 'Bi', 'Br', 'C', 'Ca',\n",
       "        'Cd', 'Ce', 'Cl', 'Co', 'Cr', 'Cs', 'Cu', 'Dy', 'Er', 'Eu', 'F',\n",
       "        'Fe', 'Ga', 'Gd', 'Ge', 'Hf', 'Hg', 'Ho', 'I', 'In', 'Ir', 'K',\n",
       "        'La', 'Li', 'Lu', 'Mg', 'Mn', 'Mo', 'N', 'Na', 'Nb', 'Nd', 'Ni',\n",
       "        'O', 'Os', 'P', 'Pa', 'Pb', 'Pd', 'Pr', 'Pt', 'Pu', 'Rb', 'Re',\n",
       "        'Rh', 'Ru', 'S', 'Sb', 'Sc', 'Se', 'Si', 'Sn', 'Sr', 'Ta', 'Tb',\n",
       "        'Tc', 'Te', 'Th', 'Ti', 'Tl', 'U', 'V', 'W', 'Xe', 'Y', 'Yb', 'Zn',\n",
       "        'Zr'], dtype='<U2'))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elements = get_all_elements(df)\n",
    "nchannel = len(elements)\n",
    "nchannel, elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81073"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = VoxelNet(nchannel)\n",
    "count_parameters(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Cartesian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1784, 13) (199, 13)\n",
      "Initialised MolLoader with 1784 compounds.\n",
      "    sigma=0.1, L=12.8, N=32, nchannel=79, mode=cartesian, shuffle=True, rotate=True, device=cuda\n",
      "Initialised MolLoader with 199 compounds.\n",
      "    sigma=0.1, L=12.8, N=32, nchannel=79, mode=cartesian, shuffle=False, rotate=False, device=cuda\n",
      "Epoch 0: train loss 9.042786598205566 val loss 3.4420368671417236\n",
      "Epoch 1: train loss 2.2276499271392822 val loss 2.301090717315674\n",
      "Epoch 2: train loss 2.0687930583953857 val loss 2.1955337524414062\n",
      "Epoch 3: train loss 1.8766776323318481 val loss 1.9986697435379028\n",
      "Epoch 4: train loss 1.3838999271392822 val loss 1.1128392219543457\n",
      "Epoch 5: train loss 0.6126717925071716 val loss 0.6515576243400574\n",
      "Epoch 6: train loss 0.3997688591480255 val loss 0.6038097739219666\n",
      "Epoch 7: train loss 0.42647045850753784 val loss 0.5344315767288208\n",
      "Epoch 8: train loss 0.39392220973968506 val loss 0.4994639456272125\n",
      "Epoch 9: train loss 0.33262431621551514 val loss 0.48317447304725647\n",
      "Epoch 10: train loss 0.33407914638519287 val loss 0.5278033018112183\n",
      "Epoch 11: train loss 0.32470840215682983 val loss 0.4564822018146515\n",
      "Epoch 12: train loss 0.3020687401294708 val loss 0.4546253979206085\n",
      "Epoch 13: train loss 0.3074149489402771 val loss 0.46799856424331665\n",
      "Epoch 14: train loss 0.2910267412662506 val loss 0.4299628436565399\n",
      "Epoch 15: train loss 0.2776440680027008 val loss 0.440646767616272\n",
      "Epoch 16: train loss 0.2631703317165375 val loss 0.4171682298183441\n",
      "Epoch 17: train loss 0.24020108580589294 val loss 0.4037395417690277\n",
      "Epoch 18: train loss 0.23293106257915497 val loss 0.4220167100429535\n",
      "Epoch 19: train loss 0.23831789195537567 val loss 0.40238699316978455\n",
      "Epoch 20: train loss 0.23322974145412445 val loss 0.4337442219257355\n",
      "Epoch 21: train loss 0.21831072866916656 val loss 0.4216398298740387\n",
      "Epoch 22: train loss 0.21869061887264252 val loss 0.3678843379020691\n",
      "Epoch 23: train loss 0.19900062680244446 val loss 0.37184783816337585\n",
      "Epoch 24: train loss 0.19336916506290436 val loss 0.3896147906780243\n",
      "Epoch 25: train loss 0.17377294600009918 val loss 0.38190487027168274\n",
      "Epoch 26: train loss 0.17475265264511108 val loss 0.3595266044139862\n",
      "Epoch 27: train loss 0.180635005235672 val loss 0.3569500744342804\n",
      "Epoch 28: train loss 0.19299036264419556 val loss 0.4130136966705322\n",
      "Epoch 29: train loss 0.16084669530391693 val loss 0.33798593282699585\n",
      "Epoch 30: train loss 0.14000333845615387 val loss 0.34869715571403503\n",
      "Epoch 31: train loss 0.13244952261447906 val loss 0.32535502314567566\n",
      "Epoch 32: train loss 0.12069937586784363 val loss 0.3309115171432495\n",
      "Epoch 33: train loss 0.15994518995285034 val loss 0.5063350200653076\n",
      "Epoch 34: train loss 0.14764055609703064 val loss 0.3193380534648895\n",
      "Epoch 35: train loss 0.13594861328601837 val loss 0.43233391642570496\n",
      "Epoch 36: train loss 0.12074971199035645 val loss 0.31162145733833313\n",
      "Epoch 37: train loss 0.09962089359760284 val loss 0.32645124197006226\n",
      "Epoch 38: Batch 23/28 processed.      \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-db81201f1872>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m                shuffle=False, rotate_randomly=False, device=device, reduce_data=True, mode='cartesian')\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mml_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mml_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.00\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\InterDiscProj\\ML_utils.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(epochs, model, train_loader, val_loader, opt, lr, weight_decay, verbose)\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[0mcounter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m             \u001b[1;31m# print(names)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m             \u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\InterDiscProj\\molloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m          \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\InterDiscProj\\molloader.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    161\u001b[0m                     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0melement\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSG\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreciprocal_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'cartesian'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m                             \u001b[0mdescriptor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_voxel_grid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m                         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'spherical'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m                             \u001b[0mdescriptor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_spherical_voxel_grid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\InterDiscProj\\voxel.py\u001b[0m in \u001b[0;36mmake_voxel_grid\u001b[1;34m(G, SG, L, N, rot)\u001b[0m\n\u001b[0;32m    478\u001b[0m     \u001b[0mRG\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 480\u001b[1;33m     \u001b[0mI\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRG\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mgrid_width\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mvoxel_width\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    481\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sigma = 0.1\n",
    "L = 12.8\n",
    "N = 32\n",
    "epochs = 50\n",
    "device = get_default_device()\n",
    "\n",
    "\n",
    "seed_everything()\n",
    "train_df, test_df = train_test_split(df, test_size=0.1)\n",
    "print(train_df.shape, test_df.shape)\n",
    "\n",
    "seed_everything()\n",
    "\n",
    "net = VoxelNet(nchannel)\n",
    "net = net.to(device)\n",
    "\n",
    "ml_train = MolLoader(train_df, sigma=sigma, elements=elements,\n",
    "               L=L, N=N, batch_size=64, nchannel=nchannel,\n",
    "               shuffle=True, rotate_randomly=True, device=device, reduce_data=True, mode='cartesian')\n",
    "\n",
    "ml_test = MolLoader(test_df, sigma=sigma, elements=elements,\n",
    "               L=L, N=N, batch_size=128, nchannel=nchannel,\n",
    "               shuffle=False, rotate_randomly=False, device=device, reduce_data=True, mode='cartesian')\n",
    "\n",
    "fit(epochs, net, ml_train, ml_test, torch.optim.Adam, lr=0.001, weight_decay=0.00)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.1146\n",
    "ml_pred = ml_train\n",
    "ml_pred.reset(batch_size=128, shuffle=False, rotate_randomly=False)\n",
    "ys, y_hats = predict(net, ml_pred)\n",
    "plot_predictions(ys, y_hats)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.0727\n",
    "# rotations\n",
    "seed_everything()\n",
    "ml_pred = ml_train\n",
    "ml_pred.reset(batch_size=128, shuffle=False, rotate_randomly=True)\n",
    "ys, y_hats = predict_epochs(net, ml_pred, epochs=5)\n",
    "plot_predictions(ys, y_hats, alpha=0.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.3196\n",
    "ml_pred = ml_test\n",
    "ml_pred.reset(batch_size=128, shuffle=False, rotate_randomly=False)\n",
    "ys, y_hats = predict(net, ml_pred)\n",
    "plot_predictions(ys, y_hats)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.2865\n",
    "# rotations\n",
    "seed_everything()\n",
    "ml_pred = ml_test\n",
    "ml_pred.reset(batch_size=128, shuffle=False, rotate_randomly=True)\n",
    "ys, y_hats = predict_epochs(net, ml_pred, epochs=5)\n",
    "plot_predictions(ys, y_hats)\n",
    "plt.savefig(fig_folder + data_name + \"_cartesian_test.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spherical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 0.1\n",
    "L = 12.8\n",
    "N = 32\n",
    "epochs = 50\n",
    "device = get_default_device()\n",
    "\n",
    "\n",
    "seed_everything()\n",
    "train_df, test_df = train_test_split(df, test_size=0.1)\n",
    "print(train_df.shape, test_df.shape)\n",
    "\n",
    "seed_everything()\n",
    "\n",
    "net = VoxelNet(nchannel)\n",
    "net = net.to(device)\n",
    "\n",
    "ml_train = MolLoader(train_df, sigma=sigma, elements=elements,\n",
    "               L=L, N=N, batch_size=64, nchannel=nchannel,\n",
    "               shuffle=True, rotate_randomly=True, device=device, reduce_data=True, mode='spherical')\n",
    "\n",
    "ml_test = MolLoader(test_df, sigma=sigma, elements=elements,\n",
    "               L=L, N=N, batch_size=128, nchannel=nchannel,\n",
    "               shuffle=False, rotate_randomly=False, device=device, reduce_data=True, mode='spherical')\n",
    "\n",
    "fit(epochs, net, ml_train, ml_test, torch.optim.Adam, lr=0.001, weight_decay=0.00)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.0723\n",
    "ml_pred = ml_train\n",
    "ml_pred.reset(batch_size=128, shuffle=False, rotate_randomly=False)\n",
    "ys, y_hats = predict(net, ml_pred)\n",
    "plot_predictions(ys, y_hats)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.0669\n",
    "# rotations\n",
    "seed_everything()\n",
    "ml_pred = ml_train\n",
    "ml_pred.reset(batch_size=128, shuffle=False, rotate_randomly=True)\n",
    "ys, y_hats = predict_epochs(net, ml_pred, epochs=5)\n",
    "plot_predictions(ys, y_hats, alpha=0.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything()\n",
    "ml_wrong_mode_pred = MolLoader(train_df, sigma=sigma, elements=elements,\n",
    "               L=L, N=N, batch_size=128, nchannel=nchannel,\n",
    "               shuffle=False, rotate_randomly=True, device=device, reduce_data=True, mode='cartesian')\n",
    "ys, y_hats = predict_epochs(net, ml_wrong_mode_pred, epochs=5)\n",
    "plot_predictions(ys, y_hats, alpha=0.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.2716\n",
    "ml_pred = ml_test\n",
    "ml_pred.reset(batch_size=128, shuffle=False, rotate_randomly=False)\n",
    "ys, y_hats = predict(net, ml_pred)\n",
    "plot_predictions(ys, y_hats)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.2629\n",
    "# rotations\n",
    "seed_everything()\n",
    "ml_pred = ml_test\n",
    "ml_pred.reset(batch_size=128, shuffle=False, rotate_randomly=True)\n",
    "ys, y_hats = predict_epochs(net, ml_pred, epochs=5)\n",
    "plot_predictions(ys, y_hats)\n",
    "plt.savefig(fig_folder + data_name + \"_spherical_test.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cartesian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 0.1\n",
    "L = 12.8\n",
    "N = 32\n",
    "epochs = 5\n",
    "device = get_default_device()\n",
    "\n",
    "seed_everything()\n",
    "all_ys = []\n",
    "all_y_hats = []\n",
    "\n",
    "all_train_ys = []\n",
    "all_train_y_hats = []\n",
    "\n",
    "for train_indices, test_indices in KFold(n_splits=5, shuffle=True).split(df):\n",
    "    \n",
    "    train_df = df.iloc[train_indices]\n",
    "    test_df = df.iloc[test_indices]\n",
    "\n",
    "    net = VoxelNet(nchannel)\n",
    "    net = net.to(device)\n",
    "    \n",
    "    ml_train = MolLoader(train_df, sigma=sigma, elements=elements,\n",
    "               L=L, N=N, batch_size=64, nchannel=nchannel,\n",
    "               shuffle=True, rotate_randomly=True, device=device, reduce_data=True, mode='cartesian')\n",
    "\n",
    "    ml_test = MolLoader(test_df, sigma=sigma, elements=elements,\n",
    "               L=L, N=N, batch_size=128, nchannel=nchannel,\n",
    "               shuffle=False, rotate_randomly=False, device=device, reduce_data=True, mode='cartesian')\n",
    "    \n",
    "    fit(epochs, net, ml_train, ml_test, torch.optim.Adam, lr=0.001, weight_decay=0)\n",
    "    \n",
    "    ml_pred = ml_train\n",
    "    ml_pred.reset(batch_size=128, shuffle=False, rotate_randomly=True)\n",
    "    ys, y_hats = predict_epochs(net, ml_pred, epochs=5)\n",
    "    plot_predictions(ys, y_hats)\n",
    "    plt.show()\n",
    "    all_train_ys.append(ys)\n",
    "    all_train_y_hats.append(y_hats)\n",
    "    \n",
    "    ml_pred = ml_test\n",
    "    ml_pred.reset(batch_size=128, shuffle=False, rotate_randomly=True)\n",
    "    ys, y_hats = predict_epochs(net, ml_pred, epochs=5)\n",
    "    plot_predictions(ys, y_hats)\n",
    "    plt.show()\n",
    "    all_ys.append(ys)\n",
    "    all_y_hats.append(y_hats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions(np.hstack(all_train_ys), np.hstack(all_train_y_hats), alpha=0.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.2881\n",
    "plot_predictions(np.hstack(all_ys), np.hstack(all_y_hats), alpha=0.01)\n",
    "plt.savefig(fig_folder + data_name + \"_cartesian_cv.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spherical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 0.1\n",
    "L = 12.8\n",
    "N = 32\n",
    "epochs = 5\n",
    "device = get_default_device()\n",
    "\n",
    "seed_everything()\n",
    "all_ys = []\n",
    "all_y_hats = []\n",
    "\n",
    "all_train_ys = []\n",
    "all_train_y_hats = []\n",
    "\n",
    "for train_indices, test_indices in KFold(n_splits=5, shuffle=True).split(df):\n",
    "    \n",
    "    train_df = df.iloc[train_indices]\n",
    "    test_df = df.iloc[test_indices]\n",
    "\n",
    "    net = VoxelNet(nchannel)\n",
    "    net = net.to(device)\n",
    "    \n",
    "    ml_train = MolLoader(train_df, sigma=sigma, elements=elements,\n",
    "               L=L, N=N, batch_size=64, nchannel=nchannel,\n",
    "               shuffle=True, rotate_randomly=True, device=device, reduce_data=True, mode='spherical')\n",
    "\n",
    "    ml_test = MolLoader(test_df, sigma=sigma, elements=elements,\n",
    "               L=L, N=N, batch_size=128, nchannel=nchannel,\n",
    "               shuffle=False, rotate_randomly=False, device=device, reduce_data=True, mode='spherical')\n",
    "    \n",
    "    fit(epochs, net, ml_train, ml_test, torch.optim.Adam, lr=0.001, weight_decay=0)\n",
    "    \n",
    "    ml_pred = ml_train\n",
    "    ml_pred.reset(batch_size=128, shuffle=False, rotate_randomly=True)\n",
    "    ys, y_hats = predict_epochs(net, ml_pred, epochs=5)\n",
    "    plot_predictions(ys, y_hats)\n",
    "    plt.show()\n",
    "    all_train_ys.append(ys)\n",
    "    all_train_y_hats.append(y_hats)\n",
    "    \n",
    "    ml_pred = ml_test\n",
    "    ml_pred.reset(batch_size=128, shuffle=False, rotate_randomly=True)\n",
    "    ys, y_hats = predict_epochs(net, ml_pred, epochs=5)\n",
    "    plot_predictions(ys, y_hats)\n",
    "    plt.show()\n",
    "    all_ys.append(ys)\n",
    "    all_y_hats.append(y_hats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.2658\n",
    "plot_predictions(np.hstack(all_ys), np.hstack(all_y_hats), alpha=0.01)\n",
    "plt.savefig(fig_folder + data_name + \"_spherical_cv.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything()\n",
    "train_df, test_df = train_test_split(df, test_size=0.1)\n",
    "print(train_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = ParameterGrid({\n",
    "    \"sigma\": [0.01, 0.1, 0.5, 1.],\n",
    "    \"L\": [10, 12.8, 15],\n",
    "    \"weight_decay\": [0., 0.001, 0.01]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(param_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "N = 32\n",
    "\n",
    "device = get_default_device()\n",
    "\n",
    "results = []\n",
    "\n",
    "for i, params in enumerate(param_grid):\n",
    "    L = params[\"L\"]\n",
    "    sigma = params[\"sigma\"]\n",
    "    weight_decay = params[\"weight_decay\"]\n",
    "    print(f\"{i}. L = {L}, sigma = {sigma}, weight_decay = {weight_decay}\")\n",
    "\n",
    "    seed_everything()\n",
    "    \n",
    "    net = VoxelNet(nchannel)\n",
    "    net = net.to(device)\n",
    "\n",
    "    ml_train = MolLoader(train_df, sigma=sigma, elements=elements,\n",
    "                   L=L, N=N, batch_size=64, nchannel=nchannel,\n",
    "                   shuffle=True, rotate_randomly=True, device=device, reduce_data=True, mode='cartesian')\n",
    "\n",
    "    ml_test = MolLoader(test_df, sigma=sigma, elements=elements,\n",
    "                       L=L, N=N, batch_size=128, nchannel=nchannel,\n",
    "                       shuffle=False, rotate_randomly=False, device=device, reduce_data=True, mode='cartesian')\n",
    "\n",
    "    fit(epochs, net, ml_train, ml_test, torch.optim.Adam, lr=0.001, weight_decay=weight_decay, verbose=False)\n",
    "    \n",
    "    ml_pred = ml_test\n",
    "    ml_pred.reset(batch_size=128, shuffle=False, rotate_randomly=True)\n",
    "    ys, y_hats = predict_epochs(net, ml_pred, epochs=5)\n",
    "    plot_predictions(ys, y_hats)\n",
    "    \n",
    "    results.append(np.mean((ys - y_hats)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param, mse in zip(param_grid, results):\n",
    "    print(param, mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amin = np.argmin(results)\n",
    "param_grid[amin], results[amin]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
